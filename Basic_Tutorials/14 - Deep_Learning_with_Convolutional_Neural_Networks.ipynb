{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Convolutional Neural Networks (CNNs)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Convolutional Neural Networks (CNNs) have revolutionized the field of computer vision. They are designed to process data with a grid-like topology, such as images, and have been instrumental in advancing image recognition tasks. In this tutorial, we'll delve into the architecture of CNNs, understand the roles of convolutional and pooling layers, and implement CNN models for image recognition tasks using Python and popular deep learning frameworks.\n",
    "\n",
    "![CNN Architecture](https://www.researchgate.net/profile/Aftab-Alam-38/publication/344294512/figure/fig1/AS:936958935191552@1600399826350/A-generic-CNN-Architecture.png)\n",
    "\n",
    "*Image Source: [Researchgate](https://www.researchgate.net/figure/A-generic-CNN-Architecture_fig1_344294512)*\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Understanding Convolutional Neural Networks](#1)\n",
    "   - [The Convolution Operation](#1.1)\n",
    "   - [Mathematical Foundation](#1.2)\n",
    "2. [Key Components of CNNs](#2)\n",
    "   - [Convolutional Layers](#2.1)\n",
    "   - [Activation Functions](#2.2)\n",
    "   - [Pooling Layers](#2.3)\n",
    "   - [Fully Connected Layers](#2.4)\n",
    "3. [Implementing a CNN for Image Recognition](#3)\n",
    "   - [Dataset Preparation](#3.1)\n",
    "   - [Building the CNN Model](#3.2)\n",
    "   - [Training the Model](#3.3)\n",
    "   - [Evaluating Performance](#3.4)\n",
    "4. [Advanced CNN Architectures](#4)\n",
    "   - [VGGNet](#4.1)\n",
    "   - [ResNet](#4.2)\n",
    "   - [Inception Networks](#4.3)\n",
    "5. [Recent Developments in CNNs](#5)\n",
    "   - [MobileNet](#5.1)\n",
    "   - [EfficientNet](#5.2)\n",
    "6. [Applications of CNNs](#6)\n",
    "7. [Conclusion](#7)\n",
    "8. [References](#8)\n",
    "\n",
    "<a id=\"1\"></a>\n",
    "## 1. Understanding Convolutional Neural Networks\n",
    "\n",
    "CNNs are a class of deep neural networks that have proven very effective in areas such as image recognition and classification. Introduced by Yann LeCun in the 1990s with the LeNet architecture for digit recognition [[1]](#ref1), CNNs have evolved to solve complex tasks with higher accuracy.\n",
    "\n",
    "### Advantages of CNNs:\n",
    "\n",
    "- **Parameter Sharing**: Convolutional layers share weights, reducing the number of parameters.\n",
    "- **Spatial Hierarchy**: Captures spatial hierarchies in data through local connections and pooling.\n",
    "\n",
    "<a id=\"1.1\"></a>\n",
    "### The Convolution Operation\n",
    "\n",
    "At the core of CNNs is the convolution operation, which involves sliding a filter (kernel) over the input data to produce feature maps.\n",
    "\n",
    "![Convolution Operation](https://miro.medium.com/v2/resize:fit:640/format:webp/1*P8NDaw0meni6bU4A5c2BZg.jpeg)\n",
    "\n",
    "*Image Source: [Medium](https://medium.com/@kinisanketh/getting-started-with-cnn-18c03efc7d06)*\n",
    "\n",
    "<a id=\"1.2\"></a>\n",
    "### Mathematical Foundation\n",
    "\n",
    "The convolution operation for a 2D input and a 2D kernel is defined as:\n",
    "\n",
    "$$[\n",
    "S(i, j) = (I * K)(i, j) = \\sum_{m} \\sum_{n} I(m, n) \\cdot K(i - m, j - n)\n",
    "]$$\n",
    "\n",
    "Where:\n",
    "- $( I )$ is the input image.\n",
    "- $( K )$ is the kernel (filter).\n",
    "- $( S )$ is the feature map.\n",
    "\n",
    "<a id=\"2\"></a>\n",
    "## 2. Key Components of CNNs\n",
    "\n",
    "<a id=\"2.1\"></a>\n",
    "### 2.1 Convolutional Layers\n",
    "\n",
    "Convolutional layers apply a set of filters to the input data, extracting features like edges, textures, and shapes.\n",
    "\n",
    "- **Stride**: The number of pixels by which the filter moves across the input matrix.\n",
    "- **Padding**: Adding zeros around the input matrix to preserve the spatial dimensions.\n",
    "\n",
    "<a id=\"2.2\"></a>\n",
    "### 2.2 Activation Functions\n",
    "\n",
    "Activation functions introduce non-linearity into the network. The most commonly used is the Rectified Linear Unit (ReLU):\n",
    "\n",
    "$$[\n",
    "\\text{ReLU}(x) = \\max(0, x)\n",
    "]$$\n",
    "\n",
    "<a id=\"2.3\"></a>\n",
    "### 2.3 Pooling Layers\n",
    "\n",
    "Pooling layers reduce the spatial dimensions of the feature maps, retaining the most important information.\n",
    "\n",
    "- **Max Pooling**: Takes the maximum value in a pooling window.\n",
    "- **Average Pooling**: Takes the average of values in a pooling window.\n",
    "\n",
    "<a id=\"2.4\"></a>\n",
    "### 2.4 Fully Connected Layers\n",
    "\n",
    "After several convolutional and pooling layers, the high-level reasoning is performed via fully connected layers.\n",
    "\n",
    "<a id=\"3\"></a>\n",
    "## 3. Implementing a CNN for Image Recognition\n",
    "\n",
    "We'll implement a CNN using TensorFlow and Keras to classify images from the CIFAR-10 dataset.\n",
    "\n",
    "<a id=\"3.1\"></a>\n",
    "### 3.1 Dataset Preparation\n",
    "\n",
    "The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the data\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.2\"></a>\n",
    "\n",
    "### 3.2 Building the CNN Model\n",
    "We'll define a simple CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Flatten and add fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))  # CIFAR-10 has 10 classes\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.3\"></a>\n",
    "\n",
    "### 3.3 Training the Model\n",
    "Compile and train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4\"></a>\n",
    "\n",
    "### 3.4 Evaluating Performance\n",
    "Plot training and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "\n",
    "## 4. Advanced CNN Architectures\n",
    "<a id=\"4.1\"></a>\n",
    "\n",
    "### 4.1 VGGNet\n",
    "VGGNet [2] introduced by Simonyan and Zisserman uses very small convolution filters (3x3) and showed that increasing depth improves performance.\n",
    "\n",
    "![VGGNet](https://miro.medium.com/v2/resize:fit:720/format:webp/1*hs8Ud3X2LBzf5XMAFTmGGw.jpeg)\n",
    "\n",
    "*Image Source: [Medium](https://medium.com/analytics-vidhya/vggnet-convolutional-network-for-classification-and-detection-3543aaf61699)*\n",
    "\n",
    "\n",
    "<a id=\"4.2\"></a>\n",
    "\n",
    "### 4.2 ResNet\n",
    "ResNet [3] introduced residual learning with skip connections to train very deep networks.\n",
    "\n",
    "![ResNet](https://miro.medium.com/v2/resize:fit:720/format:webp/1*9SrzCTHIVgxzPu3VmvWmVw.png)\n",
    "\n",
    "*Image Source: [Medium](https://medium.com/@nayanchaure601/variants-of-resnet-a-comparative-analysis-63fdc1573b34)*\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"4.3\"></a>\n",
    "\n",
    "### 4.3 Inception Networks\n",
    "Inception networks [4] use parallel convolutional layers with different filter sizes to capture various spatial features.\n",
    "\n",
    "![Inception](https://www.researchgate.net/profile/Alwin-Poulose/publication/369643206/figure/fig2/AS:11431281132222522@1680205413374/CNN-Inception-Convolution-neural-network-with-Inception-module.ppm)\n",
    "\n",
    "*Image Source: [Researchgate](https://www.researchgate.net/figure/CNN-Inception-Convolution-neural-network-with-Inception-module_fig2_369643206)*\n",
    "\n",
    "<a id=\"5\"></a>\n",
    "\n",
    "## 5. Recent Developments in CNNs\n",
    "<a id=\"5.1\"></a>\n",
    "\n",
    "### 5.1 MobileNet\n",
    "MobileNet [5] introduces depthwise separable convolutions to build lightweight networks suitable for mobile devices.\n",
    "\n",
    "<a id=\"5.2\"></a>\n",
    "\n",
    "### 5.2 EfficientNet\n",
    "EfficientNet [6] uses a compound scaling method to scale up CNNs in a balanced way.\n",
    "\n",
    "<a id=\"6\"></a>\n",
    "\n",
    "## 6. Applications of CNNs\n",
    "\n",
    "![Application](https://miro.medium.com/v2/resize:fit:720/format:webp/1*Ns_ySM3uFCuxCLXD3rmOgQ.png)\n",
    "\n",
    "*Image Source: [Medium](https://medium.com/ibm-data-ai/faster-r-cnn-vs-yolo-vs-ssd-object-detection-algorithms-18badb0e02dc)*\n",
    "\n",
    "Image Classification: Assigning labels to images.\n",
    "Object Detection: Identifying objects within images.\n",
    "Semantic Segmentation: Classifying each pixel in an image.\n",
    "<a id=\"7\"></a>\n",
    "\n",
    "## 7. Conclusion\n",
    "CNNs have dramatically improved the capabilities of image recognition systems. Understanding their architecture and components is crucial for leveraging their power in various applications.\n",
    "\n",
    "<a id=\"8\"></a>\n",
    "\n",
    "## 8. References\n",
    "- <a id=\"ref1\"></a>Y. LeCun et al., \"Gradient-based learning applied to document recognition,\" Proceedings of the IEEE, 1998.\n",
    "- <a id=\"ref2\"></a>K. Simonyan and A. Zisserman, \"Very Deep Convolutional Networks for Large-Scale Image Recognition,\" arXiv preprint arXiv:1409.1556, 2014.\n",
    "- <a id=\"ref3\"></a>K. He et al., \"Deep Residual Learning for Image Recognition,\" CVPR, 2016.\n",
    "- <a id=\"ref4\"></a>C. Szegedy et al., \"Going Deeper with Convolutions,\" CVPR, 2015.\n",
    "- <a id=\"ref5\"></a>A. G. Howard et al., \"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,\" arXiv preprint arXiv:1704.04861, 2017.\n",
    "- <a id=\"ref6\"></a>M. Tan and Q. V. Le, \"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,\" ICML, 2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
