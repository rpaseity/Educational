{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems with Neural Networks\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Recommender systems have become an integral part of modern online experiences, guiding users towards products, services, and content tailored to their preferences. With the advent of deep learning, recommender systems have evolved significantly, leveraging complex neural network architectures to capture intricate patterns in user behavior.\n",
    "\n",
    "In this tutorial, we'll explore how to build personalized recommender systems using deep learning techniques such as matrix factorization and deep collaborative filtering. We'll delve into the underlying mathematics, implement models using Python and PyTorch, and discuss the latest developments in the field. Key papers and relevant imagery will be included to enhance understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Understanding Recommender Systems](#1)\n",
    "   - [Types of Recommender Systems](#1.1)\n",
    "   - [Challenges in Recommendation](#1.2)\n",
    "2. [Matrix Factorization](#2)\n",
    "   - [Singular Value Decomposition (SVD)](#2.1)\n",
    "   - [Alternating Least Squares (ALS)](#2.2)\n",
    "   - [Implementation of Matrix Factorization](#2.3)\n",
    "3. [Neural Collaborative Filtering](#3)\n",
    "   - [Generalized Matrix Factorization (GMF)](#3.1)\n",
    "   - [Neural Matrix Factorization (NeuMF)](#3.2)\n",
    "   - [Implementation of Neural Collaborative Filtering](#3.3)\n",
    "4. [Autoencoders for Recommendation](#4)\n",
    "   - [Denoising Autoencoders](#4.1)\n",
    "   - [Variational Autoencoders (VAE)](#4.2)\n",
    "   - [Implementation of Autoencoder-based Recommender](#4.3)\n",
    "5. [Latest Developments](#5)\n",
    "   - [Graph Neural Networks for Recommendation](#5.1)\n",
    "   - [Self-Attention Mechanisms](#5.2)\n",
    "6. [Conclusion](#6)\n",
    "7. [References](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# 1. Understanding Recommender Systems\n",
    "\n",
    "Recommender systems aim to predict users' preferences and suggest items they are likely to find interesting. They play a crucial role in various domains, including e-commerce, streaming services, and social media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "## 1.1 Types of Recommender Systems\n",
    "\n",
    "### Content-Based Filtering\n",
    "\n",
    "- **Definition**: Recommends items similar to those a user liked in the past.\n",
    "- **Approach**: Uses item features and user profiles.\n",
    "\n",
    "### Collaborative Filtering\n",
    "\n",
    "- **Definition**: Recommends items based on the preferences of similar users.\n",
    "- **Approach**: Utilizes user-item interaction data (e.g., ratings, clicks).\n",
    "\n",
    "### Hybrid Methods\n",
    "\n",
    "- Combines content-based and collaborative filtering to leverage the strengths of both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "## 1.2 Challenges in Recommendation\n",
    "\n",
    "- **Data Sparsity**: Most users interact with a small subset of items.\n",
    "- **Cold Start Problem**: Difficulty in recommending for new users or items.\n",
    "- **Scalability**: Managing large-scale datasets with millions of users and items.\n",
    "- **Diversity and Serendipity**: Balancing between accurate recommendations and novel content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# 2. Matrix Factorization\n",
    "\n",
    "Matrix factorization is a collaborative filtering technique that decomposes the user-item interaction matrix into latent factors representing users and items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.1\"></a>\n",
    "## 2.1 Singular Value Decomposition (SVD)\n",
    "\n",
    "SVD decomposes a matrix $( R )$ into the product of three matrices:\n",
    "\n",
    "$[\n",
    "R = U \\Sigma V^T\n",
    "]$\n",
    "\n",
    "- $( U )$: User factors.\n",
    "- $( \\Sigma )$: Diagonal matrix of singular values.\n",
    "- $( V^T )$: Item factors.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Not suitable for sparse matrices.\n",
    "- Requires imputation of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.2\"></a>\n",
    "## 2.2 Alternating Least Squares (ALS)\n",
    "\n",
    "ALS optimizes the following objective function:\n",
    "\n",
    "$[\n",
    "\\min_{P,Q} \\sum_{(u,i) \\in K} (R_{ui} - P_u^T Q_i)^2 + \\lambda (\\| P_u \\|^2 + \\| Q_i \\|^2)\n",
    "]$\n",
    "\n",
    "- $( R_{ui} )$: Rating of user $( u )$ for item $( i )$.\n",
    "- $( P_u )$: Latent vector for user $( u )$.\n",
    "- $( Q_i )$: Latent vector for item $( i )$.\n",
    "- $( \\lambda )$: Regularization parameter.\n",
    "- $( K )$: Set of known ratings.\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. Initialize user and item factors randomly.\n",
    "2. Fix item factors and solve for user factors.\n",
    "3. Fix user factors and solve for item factors.\n",
    "4. Repeat until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.3\"></a>\n",
    "## 2.3 Implementation of Matrix Factorization\n",
    "\n",
    "We'll implement ALS using Python and NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy pandas torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Load dataset\n",
    "# For demonstration, we'll use the MovieLens 100k dataset\n",
    "# Download from: https://grouplens.org/datasets/movielens/100k/\n",
    "\n",
    "# Read data\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Create user-item matrix\n",
    "R_df = ratings.pivot(index='user_id', columns='item_id', values='rating').fillna(0)\n",
    "R = R_df.values\n",
    "user_ratings_mean = np.mean(R, axis=1)\n",
    "R_demeaned = R - user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "# Perform SVD\n",
    "U, sigma, Vt = svds(R_demeaned, k=50)\n",
    "\n",
    "# Reconstruct ratings\n",
    "sigma = np.diag(sigma)\n",
    "predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "preds_df = pd.DataFrame(predicted_ratings, columns=R_df.columns)\n",
    "\n",
    "# Function to recommend movies\n",
    "def recommend_movies(predictions_df, user_id, movies_df, original_ratings_df, num_recommendations=5):\n",
    "    # Get and sort user's predictions\n",
    "    user_row_number = user_id - 1\n",
    "    sorted_user_predictions = predictions_df.iloc[user_row_number].sort_values(ascending=False)\n",
    "    \n",
    "    # Get user's data and merge with movies\n",
    "    user_data = original_ratings_df[original_ratings_df.user_id == user_id]\n",
    "    user_full = user_data.merge(movies_df, how='left', left_on='item_id', right_on='movie_id').sort_values(['rating'], ascending=False)\n",
    "    \n",
    "    print('User {0} has already rated {1} movies.'.format(user_id, user_full.shape[0]))\n",
    "    print('Recommending highest predicted ratings movies not already rated.')\n",
    "    \n",
    "    # Recommend movies\n",
    "    recommendations = movies_df[~movies_df['movie_id'].isin(user_full['movie_id'])]\n",
    "    recommendations = recommendations.merge(pd.DataFrame(sorted_user_predictions).reset_index(), how='left', left_on='movie_id', right_on='item_id')\n",
    "    recommendations = recommendations.rename(columns={user_row_number: 'Predictions'}).sort_values('Predictions', ascending=False)\n",
    "    \n",
    "    return user_full, recommendations.head(num_recommendations)\n",
    "\n",
    "# Load movies data\n",
    "movies_df = pd.read_csv('ml-100k/u.item', sep='|', encoding='latin-1', names=['movie_id', 'title'], usecols=[0, 1])\n",
    "\n",
    "# Recommend movies for a user\n",
    "already_rated, predictions = recommend_movies(preds_df, 837, movies_df, ratings, 5)\n",
    "\n",
    "print('Top 5 movie recommendations:')\n",
    "print(predictions[['title', 'Predictions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- We load the MovieLens 100k dataset.\n",
    "- Create a user-item matrix and perform SVD.\n",
    "- Reconstruct the predicted ratings.\n",
    "- Recommend movies to a user based on predicted ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "# 3. Neural Collaborative Filtering\n",
    "\n",
    "Neural Collaborative Filtering (NCF) [[1]](#ref1) leverages neural networks to model user-item interactions, providing greater expressiveness than traditional matrix factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "## 3.1 Generalized Matrix Factorization (GMF)\n",
    "\n",
    "GMF replaces the dot product in traditional matrix factorization with a neural network.\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "- **Embedding Layers**: Map users and items to latent vectors.\n",
    "- **Element-wise Multiplication**: Combine user and item embeddings.\n",
    "- **Output Layer**: Predict interaction (e.g., rating).\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "$[\n",
    "\\hat{y}_{ui} = h(P_u \\odot Q_i)\n",
    "]$\n",
    "\n",
    "- $( P_u )$: User embedding.\n",
    "- $( Q_i )$: Item embedding.\n",
    "- $( \\odot )$: Element-wise multiplication.\n",
    "- $( h )$: Activation function (e.g., sigmoid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.2\"></a>\n",
    "## 3.2 Neural Matrix Factorization (NeuMF)\n",
    "\n",
    "NeuMF combines GMF and Multi-Layer Perceptron (MLP) to capture both linear and nonlinear interactions.\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "- **GMF Component**: Captures linear interactions.\n",
    "- **MLP Component**: Captures nonlinear interactions.\n",
    "- **Fusion Layer**: Concatenates outputs from GMF and MLP.\n",
    "- **Output Layer**: Predicts interaction.\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "$[\n",
    "\\hat{y}_{ui} = h(\\mathbf{h}_{GMF}(u,i) \\oplus \\mathbf{h}_{MLP}(u,i))\n",
    "]$\n",
    "\n",
    "- $( \\mathbf{h}_{GMF} )$: Output from GMF.\n",
    "- $( \\mathbf{h}_{MLP} )$: Output from MLP.\n",
    "- $( \\oplus )$: Concatenation.\n",
    "- $( h )$: Activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.3\"></a>\n",
    "## 3.3 Implementation of Neural Collaborative Filtering\n",
    "\n",
    "We'll implement NeuMF using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Create dataset class\n",
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, user_tensor, item_tensor, target_tensor):\n",
    "        self.user_tensor = user_tensor\n",
    "        self.item_tensor = item_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "    def __getitem__(self, index):\n",
    "        return self.user_tensor[index], self.item_tensor[index], self.target_tensor[index]\n",
    "    def __len__(self):\n",
    "        return self.user_tensor.size(0)\n",
    "\n",
    "# Define NeuMF model\n",
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim_mf=8, latent_dim_mlp=8, layers=[16, 8, 4]):\n",
    "        super(NeuMF, self).__init__()\n",
    "        \n",
    "        # GMF part\n",
    "        self.embed_user_GMF = nn.Embedding(num_users, latent_dim_mf)\n",
    "        self.embed_item_GMF = nn.Embedding(num_items, latent_dim_mf)\n",
    "        \n",
    "        # MLP part\n",
    "        self.embed_user_MLP = nn.Embedding(num_users, latent_dim_mlp)\n",
    "        self.embed_item_MLP = nn.Embedding(num_items, latent_dim_mlp)\n",
    "        \n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        input_size = latent_dim_mlp * 2\n",
    "        for layer_size in layers:\n",
    "            self.fc_layers.append(nn.Linear(input_size, layer_size))\n",
    "            input_size = layer_size\n",
    "        \n",
    "        # Final prediction layer\n",
    "        predict_size = latent_dim_mf + layers[-1]\n",
    "        self.predict_layer = nn.Linear(predict_size, 1)\n",
    "    \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        # GMF part\n",
    "        user_embedding_GMF = self.embed_user_GMF(user_indices)\n",
    "        item_embedding_GMF = self.embed_item_GMF(item_indices)\n",
    "        output_GMF = user_embedding_GMF * item_embedding_GMF\n",
    "        \n",
    "        # MLP part\n",
    "        user_embedding_MLP = self.embed_user_MLP(user_indices)\n",
    "        item_embedding_MLP = self.embed_item_MLP(item_indices)\n",
    "        interaction = torch.cat((user_embedding_MLP, item_embedding_MLP), -1)\n",
    "        output_MLP = interaction\n",
    "        for fc in self.fc_layers:\n",
    "            output_MLP = nn.ReLU()(fc(output_MLP))\n",
    "        \n",
    "        # Concatenate GMF and MLP parts\n",
    "        concat = torch.cat((output_GMF, output_MLP), -1)\n",
    "        prediction = self.predict_layer(concat)\n",
    "        return prediction.squeeze()\n",
    "\n",
    "# Prepare data\n",
    "user_ids = ratings['user_id'].values - 1\n",
    "item_ids = ratings['item_id'].values - 1\n",
    "targets = ratings['rating'].values.astype(np.float32)\n",
    "\n",
    "dataset = RatingDataset(torch.tensor(user_ids), torch.tensor(item_ids), torch.tensor(targets))\n",
    "train_loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# Instantiate model\n",
    "num_users = ratings['user_id'].nunique()\n",
    "num_items = ratings['item_id'].nunique()\n",
    "model = NeuMF(num_users, num_items)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for user_ids_batch, item_ids_batch, ratings_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_ids_batch, item_ids_batch)\n",
    "        loss = criterion(outputs, ratings_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- **Data Preparation**: We prepare the user IDs, item IDs, and ratings as tensors.\n",
    "- **Model Definition**: NeuMF combines GMF and MLP architectures.\n",
    "- **Training**: We train the model using MSE loss and Adam optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "# 4. Autoencoders for Recommendation\n",
    "\n",
    "Autoencoders can be used to reconstruct user preferences, making them suitable for recommendation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.1\"></a>\n",
    "## 4.1 Denoising Autoencoders\n",
    "\n",
    "Denoising autoencoders [[2]](#ref2) learn to reconstruct input data from corrupted versions, improving robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.2\"></a>\n",
    "## 4.2 Variational Autoencoders (VAE)\n",
    "\n",
    "VAEs [[3]](#ref3) introduce probabilistic latent variables, allowing for better generalization and capturing data distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4.3\"></a>\n",
    "## 4.3 Implementation of Autoencoder-based Recommender\n",
    "\n",
    "We'll implement a simple autoencoder for collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "num_users = ratings['user_id'].nunique()\n",
    "num_items = ratings['item_id'].nunique()\n",
    "\n",
    "interaction_matrix = np.zeros((num_users, num_items))\n",
    "for row in ratings.itertuples():\n",
    "    interaction_matrix[row[1]-1, row[2]-1] = row[3]\n",
    "\n",
    "# Convert to tensor\n",
    "data = torch.FloatTensor(interaction_matrix)\n",
    "\n",
    "# Define Autoencoder model\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_items, encoding_dim=32):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Linear(num_items, encoding_dim)\n",
    "        self.decoder = nn.Linear(encoding_dim, num_items)\n",
    "    def forward(self, x):\n",
    "        encoded = nn.ReLU()(self.encoder(x))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Instantiate model\n",
    "model = AutoEncoder(num_items)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for user_ratings in data:\n",
    "        user_ratings = user_ratings.unsqueeze(0)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_ratings)\n",
    "        loss = criterion(outputs, user_ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / num_users:.4f}')\n",
    "\n",
    "# Recommend items for a user\n",
    "def recommend_ae(model, user_id, num_recommendations=5):\n",
    "    user_ratings = data[user_id-1].unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        reconstructed = model(user_ratings)\n",
    "    recommendations = reconstructed[0].numpy()\n",
    "    already_rated = np.where(user_ratings[0].numpy() > 0)[0]\n",
    "    recommendations[already_rated] = -np.inf\n",
    "    recommended_items = np.argsort(-recommendations)[:num_recommendations]\n",
    "    \n",
    "    recommended_movie_ids = recommended_items + 1\n",
    "    recommended_movies = movies_df[movies_df['movie_id'].isin(recommended_movie_ids)]\n",
    "    return recommended_movies\n",
    "\n",
    "# Recommend movies for user 837\n",
    "recommended_movies = recommend_ae(model, 837)\n",
    "print('Recommended movies:')\n",
    "print(recommended_movies['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- **Data Preparation**: Create a user-item interaction matrix.\n",
    "- **Model Definition**: Define an autoencoder with an encoder and decoder.\n",
    "- **Training**: Train the autoencoder to reconstruct user ratings.\n",
    "- **Recommendation**: Recommend items with highest reconstructed ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "# 5. Latest Developments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.1\"></a>\n",
    "## 5.1 Graph Neural Networks for Recommendation\n",
    "\n",
    "Graph Neural Networks (GNNs) [[4]](#ref4) model users and items as nodes in a graph, capturing complex relationships and interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Concepts\n",
    "\n",
    "- **Graph Representation**: Users and items connected by edges representing interactions.\n",
    "- **Message Passing**: Nodes aggregate information from neighbors.\n",
    "- **Applications**: Social recommendation, session-based recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.2\"></a>\n",
    "## 5.2 Self-Attention Mechanisms\n",
    "\n",
    "Self-attention models like Transformers [[5]](#ref5) have been applied to recommendation, capturing sequential dependencies and user behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SASRec: Self-Attentive Sequential Recommendation\n",
    "\n",
    "- **Model**: Uses self-attention to model user behavior sequences.\n",
    "- **Advantages**: Captures long-range dependencies without recurrence.\n",
    "- **Reference**: Kang & McAuley, 2018 [[6]](#ref6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "# 6. Conclusion\n",
    "\n",
    "Recommender systems are essential tools in the modern digital landscape. Deep learning techniques have significantly enhanced the capabilities of these systems, allowing for more accurate and personalized recommendations. From matrix factorization to neural collaborative filtering and autoencoders, we have explored various methods to build recommender systems using neural networks. Understanding the underlying mathematics and implementation details is crucial for developing effective models. The field continues to evolve with the incorporation of advanced architectures like GNNs and self-attention mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "# 7. References\n",
    "\n",
    "1. <a id=\"ref1\"></a>He, X., Liao, L., Zhang, H., Nie, L., Hu, X., & Chua, T.-S. (2017). *Neural Collaborative Filtering*. In Proceedings of the 26th International Conference on World Wide Web (WWW).\n",
    "2. <a id=\"ref2\"></a>Vincent, P., Larochelle, H., Bengio, Y., & Manzagol, P.-A. (2008). *Extracting and Composing Robust Features with Denoising Autoencoders*. In Proceedings of the 25th International Conference on Machine Learning (ICML).\n",
    "3. <a id=\"ref3\"></a>Kingma, D. P., & Welling, M. (2014). *Auto-Encoding Variational Bayes*. [arXiv:1312.6114](https://arxiv.org/abs/1312.6114)\n",
    "4. <a id=\"ref4\"></a>Wang, X., He, X., Wang, M., Feng, F., & Chua, T.-S. (2019). *Neural Graph Collaborative Filtering*. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval.\n",
    "5. <a id=\"ref5\"></a>Vaswani, A., et al. (2017). *Attention Is All You Need*. [arXiv:1706.03762](https://arxiv.org/abs/1706.03762)\n",
    "6. <a id=\"ref6\"></a>Kang, W.-C., & McAuley, J. (2018). *Self-Attentive Sequential Recommendation*. In IEEE International Conference on Data Mining (ICDM).\n",
    "\n",
    "---\n",
    "\n",
    "This notebook provides a comprehensive guide to building recommender systems with neural networks. You can run the code cells to see how models are implemented and experiment with different architectures and datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
